


#include <cmath>

#include "vdw.hpp"
#include "Control2.hpp"
#include "compressed_io.hpp"
#include "util.hpp"

#include "NwpwLibraryCVdwConfig.hpp"

#include "v_exc.hpp"
#include "v_dirac.hpp"
#include "cvdw_DF.hpp"

#include <iostream>
#include "iofmt.hpp"
#include <cstring>


/*
------------------------------------------------------------------------------
  NOTE ON k-POINT INDEPENDENCE OF THE VDW-DF FUNCTIONAL

  The nonlocal van der Waals correlation (vdW-DF) depends only on the
  *total* electron density rho(r) and related local response quantities
  (e.g., grad rho and q0).  No orbital- or k-resolved terms enter the
  functional.  Therefore, vdW-DF is formally independent of the Bloch
  vector k, and the vdW energy does not depend on Brillouin-zone sampling.

  Practically, the vdW kernel is evaluated using densities in real space
  and standard FFT machinery.  Although the intermediate arrays are complex
  (because FFTs are complex-valued in general), the physical quantities
  entering vdW-DF are real and contain no explicit k dependence.

  Consequence: vdW-DF can be evaluated identically for Gamma-only and
  k-point runs, using the same kernel tables and the same real-space
  density (summed over k if needed).  No special handling of k-points
  is required inside the vdW routines.
------------------------------------------------------------------------------
*/


namespace pwdft {

//private functions here

#include <cstddef>

/**********************************************
 *                                            *
 *           cvdw_DF_init_poly (C++)          *
 *                                            *
 **********************************************/
 /**
 * @brief Initialize the cubic–spline basis used for the vdW kernel interpolation.
 *
 * This routine constructs an identity matrix in the column-major array
 * `ya`, i.e., \f$ y_a(i,j)=\delta_{ij} \f$, where each column \f$j\f$ defines one
 * basis function on the q–mesh.  For each of these columns a cubic spline
 * is generated by calling `util_spline()`, and the resulting second
 * derivatives are stored in `y2a`.
 *
 * In the original Fortran implementation (vdw_DF_init_poly), this provides the
 * spline representation of the unit polynomials used to form the nonlocal
 * vdW basis set.
 *
 * @param[in]  n     Number of q–mesh points (length of x).
 * @param[in]  x     q–mesh values of length n.
 * @param[out] ya    Column-major array of size n×n containing the polynomial
 *                   basis values \f$ \delta_{ij} \f$.  (Column j stored at
 *                   &ya[j*n]).
 * @param[out] y2a   Column-major array of size n×n containing the second
 *                   derivative of each basis spline (same layout as ya).
 * @param[in]  utmp  Work array of length n used by the 1D spline driver.
 *
 * @note Equivalent to the Fortran call:
 *       `do j=1,n; call nwpw_spline(x, ya(1,j), n, yp1, ypn, y2a(1,j), utmp)`
 *       where \f$ y_a(i,j)=\delta_{ij}\f$ prior to the spline evaluation.
 */
static void cvdw_DF_init_poly(
    int n,
    const double *x,   // length n  (qmesh)
    double *ya,        // length n*n, column-major: ya(i,j) = ya[j*n + i]
    double *y2a,       // length n*n, same layout
    double *utmp       // length n (workspace)
)
{
    const double yp1 = 0.0;
    const double ypn = 0.0;

    // ya(i,j) = δ_ij, Fortran: do i=1,n; do j=1,n
    for (int j = 0; j < n; ++j)
    {
        for (int i = 0; i < n; ++i)
        {
            ya[j * n + i] = (i == j) ? 1.0 : 0.0;
        }
    }

    // Fortran: do j=1,n; call nwpw_spline(x, ya(1,j), n, yp1, ypn, y2a(1,j), utmp)
    // Column j is contiguous at &ya(j,1) → &ya[j*n]
    for (int j = 0; j < n; ++j)
    {
        util_spline(
            x,                 // xa
            &ya[j * n],        // ya(1,j)
            n,
            yp1,
            ypn,
            &y2a[j * n],       // y2a(1,j)
            utmp
        );
    }
}


/**************************************
 *                                    *
 *            cvdw_DF::init_poly       *
 *                                    *
 **************************************/
/**
 * @brief Initialize spline tables for the vdW-DF polynomial basis.
 *
 * Allocates a temporary work buffer and invokes the internal
 * @c cvdw_DF_init_poly() routine to construct the cubic–spline
 * representation of the unit polynomials on the current q–mesh.
 * The resulting spline coefficients populate the member arrays
 * `ya` and `ya2`, which are subsequently used in @ref poly() for
 * evaluating the vdW kernel functions \f$p_i(q)\f$ and their
 * derivatives.
 *
 * @note Must be called after @c qmesh has been loaded and
 *       before any vdW kernel evaluations.
 */
void cvdw_DF::init_poly()
{
    std::vector<double> utmp(Nqs);
    cvdw_DF_init_poly(Nqs, qmesh, ya, ya2, utmp.data());
}


/**************************************
 *                                    *
 *            cvdw_DF::poly            *
 *                                    *
 **************************************/
 /**
 * @brief Evaluate the vdW‐DF spline basis function \(p_i(x)\) and its derivative.
 *
 * Given a spline index @p i (Fortran 1-based) and a value @p x in
 * \([q_{\min}, q_{\max}]\), this routine evaluates the cubic‐spline
 * representation of the vdW polynomial \(p_i(x)\) and its derivative
 * \(\partial p_i / \partial x\).  The spline coefficients were
 * precomputed by init_poly() in the member arrays `ya` and `ya2`.
 *
 * If @p x lies outside the tabulation interval, both outputs are set to zero.
 *
 * @param[in]  i  1-based spline index (1 ≤ i ≤ Nqs).
 * @param[in]  x  Evaluation point.
 * @param[out] p  Value of \(p_i(x)\).
 * @param[out] dp Derivative \(\mathrm{d}p_i/\mathrm{d}x\).
 */
inline void cvdw_DF::poly(int i, double x, double &p, double &dp)
{
    // i is 1-based in Fortran, so convert to 0-based in C++:
    int idx = i - 1;

    if ((x >= qmin) && (x <= qmax))
    {
        // Fortran: nx = dsqrt(x/dbl_mb(qmesh(1)+Nqs-1)) * Nqs
        // qmesh(1) = qmesh[0]
        // qmesh(Nqs) = qmesh[Nqs-1]

        double denom = qmesh[Nqs - 1];   // same as (qmesh(1)+Nqs-1)
        double nx_f  = std::sqrt(x / denom) * Nqs;
        int nx = static_cast<int>(nx_f);

        if (nx < 1)       nx = 1;
        if (nx > Nqs - 1) nx = Nqs - 1;

        // Offsets for this i:
        // ya(1 + Nqs*(i-1))  becomes  ya[idx*Nqs + 0]
        // y2a(1 + Nqs*(i-1)) becomes  y2a[idx*Nqs + 0]
        const double *ya_i  = ya  + idx*Nqs;
        const double *y2a_i = ya2 + idx*Nqs;

        // Evaluate cubic spline and derivative
        p  = util_splint(qmesh, ya_i,  y2a_i, Nqs, nx, x);
        dp = util_dsplint(qmesh, ya_i, y2a_i, Nqs, nx, x);
    }
    else
    {
        p  = 0.0;
        dp = 0.0;
    }
}


/**************************************
 *                                    *
 *      cvdw_DF::generate_ufunc       *
 *                                    *
 **************************************/
 //theta and ufunc are complex arrays
 /**
 * @brief Build the nonlocal vdW kernel contraction \(u(G, q_i)\) from \f$\theta(G,q_j)\f$.
 *
 * This routine contracts the complex kernel amplitudes \f$\theta(G,q_j)\f$ with the
 * pretabulated radial spline data \c phi(g,q_i,q_j) (tabulated on the grid \c gphi)
 * to form the symmetric set of functions
 * \f[
 *   u(G,q_i) = \sum_j \theta(G,q_j)\, \phi(|G|; q_i,q_j),
 * \f]
 * stored in @p ufunc.  The contraction is carried out over the packed set of
 * reciprocal vectors \c Gpack and distributed over the 2D decomposition in the
 * q-index (@c j) using the associated Parallel object.
 *
 * Internally, the pretabulated kernel \c phi is interpolated along \c gphi using
 * cubic–spline data (value + second derivative) and accumulated over all
 * (i,j) pairs with the same traversal order as the original Fortran implementation.
 * After the local accumulation, a global MPI reduction is performed so that
 * @p ufunc contains the full, globally summed result on exit.
 *
 * @param[in]  nk1     Number of radial grid points for \c gphi (nk + 1).
 * @param[in]  Nqs     Number of q–mesh points (size of the vdW basis in q).
 * @param[in]  gphi    Radial grid \f$g_k\f$ used to tabulate \c phi, length @p nk1.
 * @param[in]  phi     Tabulated kernel spline data, laid out as
 *                     phi[ nk1 * 2 * Npairs ], where Npairs = Nqs*(Nqs+1)/2,
 *                     corresponding to Fortran phi(nk1,2,Npairs).
 * @param[in]  npack0  Number of packed G-vectors (length of @p Gpack and @p nxpack).
 * @param[in]  nfft3d  Leading dimension in G–space for @p theta and @p ufunc
 *                     (total FFT grid size).
 * @param[in]  Gpack   Packed magnitudes \f$|G|\f$ for the selected G-vectors,
 *                     length @p npack0.
 * @param[in]  nxpack  Precomputed spline indices into @p gphi for each packed
 *                     G-vector (1-based Fortran indices), length @p npack0.
 * @param[in]  theta   Complex kernel amplitudes \f$\theta(G,q_j)\f$, stored as
 *                     theta[ j * nfft3d + k ] with 0-based k, j, and total
 *                     size @p nfft3d * @p Nqs.
 * @param[out] ufunc   Complex result \f$u(G,q_i)\f$, same layout and size as @p theta;
 *                     on entry it is zeroed, on exit it contains the globally
 *                     reduced contraction over all ranks.
 *
 * @note The distribution over the q–index (@c j) uses myparall->taskid_j() and
 *       myparall->np_j(), matching the 2D decomposition used elsewhere in the
 *       vdW-DF implementation.
 */

void cvdw_DF::generate_ufunc(const int nk1,
                           const int Nqs,
                           const double *gphi,              // [nk1]
                           const double *phi,               // [nk1 * 2 * Npairs], Npairs = Nqs*(Nqs+1)/2
                           const int npack0,
                           const int nfft3d,
                           const double *Gpack,             // [npack0]
                           const int *nxpack,               // [npack0]
                           const std::complex<double> *theta, // [nfft3d * Nqs]
                           std::complex<double> *ufunc)       // [nfft3d * Nqs]
{
    // ---- parallel info (OpenMP-style + 2D decomp over j) ----
    const int taskid_j  = myparall->taskid_j();   // like Parallel2d_taskid_j()
    const int np_j      = myparall->np_j();       // like Parallel2d_np_j()

    // ---- zero ufunc (all G, all i) ----
    std::fill(ufunc, ufunc + static_cast<std::size_t>(nfft3d) * Nqs,
              std::complex<double>(0.0, 0.0));

    // Helper lambdas for indexing (Fortran: ufunc(k,i), theta(k,j))
    auto U = [=](int k, int i) -> std::complex<double>& {
        // k, i are 0-based; layout is (k, i) with leading dimension nfft3d
        return ufunc[i * nfft3d + k];
    };
    auto TH = [=](int k, int j) -> const std::complex<double>& {
        return theta[j * nfft3d + k];
    };

    // Number of (i,j) pairs: Nqs*(Nqs+1)/2, visited in the same order as Fortran
    int pcount = 0;
    int indx   = 0;   // 0-based; Fortran indx = 1..Npairs

    for (int j=0; j<Nqs; ++j)          // Fortran j=1..Nqs
    {
        for (int i=0; i<=j; ++i)       // Fortran i=1..j
        {
            ++indx;                        // Fortran indx = indx + 1
            const int owner = pcount;      // pcount modulo np_j

            if (owner == taskid_j)
            {
                // Pointer to φ(:, :, indx) in C layout:
                // Fortran: phi(nk1,2,Npairs)
                // => C: phi[ (indx-1)*2*nk1 + p*nk1 + k ], p=0,1 ; k=0..nk1-1
                const double *phi_block = phi + static_cast<std::size_t>(indx - 1) * 2 * nk1;

                // Loop over packed G indices, split amongst threads
                for (int k=0; k<npack0; ++k)   // Fortran k=tid+1,npack0,nthr
                {
                    const double g = Gpack[k];

                    // nxpack(k) gives an index into gphi, 1-based  fortran indx
                    const int klo = nxpack[k];      // 1-based, i.e. 1..nk
                    const int khi = klo + 1;        // 1-based, i.e., 2..nk+1

                    const int klo0 = klo - 1;       // 0-based, i.e.  0..nk-1
                    const int khi0 = khi - 1;       // 0-based, i.e.  1..nk

                    const double h = gphi[khi0] - gphi[klo0];
                    const double a = (gphi[khi0] - g) / h;
                    const double b = (g - gphi[klo0]) / h;

                    const double *phi1 = phi_block + 0 * nk1;  // φ(:,1,indx)
                    const double *phi2 = phi_block + 1 * nk1;  // φ(:,2,indx)

                    const double f =
                        a * phi1[klo0]
                      + b * phi1[khi0]
                      + ((a*a*a - a) * phi2[klo0]
                      +  (b*b*b - b) * phi2[khi0]) * h * h / 6.0;

                    //if ((k==0)) std::cout << "taskid_j=" << taskid_j << " k=" << k << " i=" << i << " j=" << j  << " f=" << f << " U=" << Efmt(13,6) << U(k,i) << " klo0=" << klo0 << " khi0=" << khi0  << std::endl;

                    // Update ufunc(k,i) and ufunc(k,j), k is 0-based
                    U(k, i) += TH(k, j) * f;
                    if (i != j)
                        U(k, j) += TH(k, i) * f;
                }
            }

            // advance pair counter and wrap over np_j (same as mod(pcount+1,np_j))
            pcount = (pcount + 1) % np_j;
        }
    }

    // OpenMP barrier in Fortran: !$OMP BARRIER
    // If you compile with OpenMP, you can add:
    // #pragma omp barrier

    // Global sum over all 2D-j tasks: D1dB_Vector_SumAll(2*Nqs*nfft3d, ufunc)
    // Treat complex array as contiguous doubles.
    const int len = 2 * Nqs * nfft3d;  // 2 for real+imag
    myparall->Vector_SumAll(2,len, reinterpret_cast<double*>(ufunc));
}



/**************************************
 *                                    *
 *     cvdw_DF::generate_rho          *
 *                                    *
 **************************************/
/**
 * @brief Construct the spin–summed electron density ρ(r) on the real–space grid.
 *
 * Given spin–resolved densities \f$n_\sigma(\mathbf{r})\f$ (with \c ispin = 1 or 2),
 * this routine forms
 * \f[
 *   \rho(\mathbf{r}) = \sum_{\sigma=1}^{\text{ispin}} n_\sigma(\mathbf{r})
 * \f]
 * and stores the result in @p rho.  A very small cutoff value
 * (1.0e-30) is always added to avoid division–by–zero situations in
 * later steps of the vdW–DF algorithm.
 *
 * @param[in]  ispin   Number of spin channels (1 or 2).
 * @param[in]  nfft3d  Total number of real–space grid points.
 * @param[in]  dn      Spin densities laid out as
 *                     dn[i + s * nfft3d], with s = 0..ispin-1.
 * @param[out] rho     Spin–summed density (size at least nfft3d).
 *
 * @note The added cutoff prevents issues in regions where the density
 *       is essentially zero.  It has negligible physical impact.
 */

void cvdw_DF::generate_rho(const int ispin,
                           const int nfft3d,
                           const double* dn,   // dn[nfft3d][ispin]
                           double* rho)
{
    const double dncut = 1.0e-30;

    // Loop i 
    for (int i=0; i<nfft3d; ++i)
    {
        // dn is laid out as dn(k, spin)
        double dn1 = dn[i +         0*nfft3d];    // dn(i,1)
        double dn2 = dn[i + (ispin-1)*nfft3d];    // dn(i,2)

        rho[i] = dn1 + dn2 + dncut;
    }

}


// C++ version of vdw_DF_Generate_potentials
/**************************************
 *                                    *
 *    cvdw_DF::generate_potentials    *
 *                                    *
 **************************************/
/**
 * @brief Accumulate the nonlocal vdW-DF contributions to
 *        the real-space energy density and potentials.
 *
 * This routine performs the final real–space contraction
 *   E_nl = 1/2 Σ_q θ(r,q) u(r,q),
 * together with corresponding functional derivatives,
 * and adds them to the caller–provided arrays @p exc, @p fn, and @p fdn.
 *
 * ---- Conceptual workflow ----
 *  1. On input, @p ufunc contains u(G,q) in a *packed complex layout*
 *     (real+imag interleaved) but stored in a larger n2ft3d buffer.
 *  2. @p ufunc is immediately unpacked and inverse-FFT’d to real space
 *     (cr_pfft3b), overwriting the input buffer.
 *  3. After the real-space transform, the imaginary parts are discarded
 *     (only the real part is meaningful for u(r,q)); the code enforces
 *     this via cr_copy().
 *  4. The resulting real-space u(r,q) is contracted with the q-dependent
 *     kernel spline factors using ::poly, and accumulated into exc, fn, fdn.
 *
 * Parallelism:
 *   The q-index j is 2D-decomposed among ranks. Local results are
 *   reduced using Parallel::Vector_SumAll.
 *
 * @param[in]  Nqs     Number of q-mesh points.
 * @param[in]  ispin   Number of spin channels (1 or 2).
 * @param[in]  nfft3d  Number of real-space grid points.
 * @param[in]  n2ft3d  Complex-buffer length for one field (2*nfft3d).
 * @param[in,out] ufunc
 *        On entry: packed complex u(G,q) stored in blocks of length n2ft3d.
 *        Inside the routine, each q-block is inverse-FFT’d to real space
 *        and overwritten in place.  After the transform, the imaginary part
 *        is ignored and the buffer is effectively holding real u(r,q).
 *
 * @param[in]  q0      q0 field (typically xce after theta stage).
 * @param[in]  drho    ∂q0/∂n_sigma (from xcp).
 * @param[in]  ddrho   ∂q0/∂(∇n_sigma) (from xxe).
 * @param[out] tmpexc  Work array (nfft3d) for local Δexc.
 * @param[out] tmpfn   Work array (nfft3d*ispin) for Δfn.
 * @param[out] tmpfdn  Work array (nfft3d*ispin) for Δfdn.
 * @param[in,out] exc  Energy density with vdW-DF contribution added.
 * @param[in,out] fn   Potential-like term with vdW-DF contribution added.
 * @param[in,out] fdn  Density-derivative term with vdW-DF contribution added.
 *
  * @par Memory layout note (packed complex buffers)
 * For each q–index j, the storage block is
 *
 *   ufunc[j * n2ft3d + 0]   = Re{ u(G0,j) }
 *   ufunc[j * n2ft3d + 1]   = Im{ u(G0,j) }
 *   ufunc[j * n2ft3d + 2]   = Re{ u(G1,j) }
 *   ufunc[j * n2ft3d + 3]   = Im{ u(G1,j) }
 *                …
 *   ufunc[j * n2ft3d + 2*k]   = Re{ u(Gk,j) }
 *   ufunc[j * n2ft3d + 2*k+1] = Im{ u(Gk,j) }
 *
 * Thus one (complex) field occupies n2ft3d = 2*nfft3d doubles.
 * The total size is Nqs * n2ft3d.
 *
 * After inverse FFT (cr_pfft3b),
 *   - only Re{u(r,j)} is meaningful;
 *   - the imaginary channel is mathematically ~0
 *     and is explicitly zeroed via cr_copy.
 *
 * @par Example for one q
 *     j = 0
 *       index:   0      1      |    2      3    |   ...
 *       value:  Re0   Im0      |   Re1   Im1    |   ...
 *
 * @par Relation to Fortran
 * The original Fortran code uses COMPLEX*16(u(NG,Nqs)) with
 * stride-NG complex layout.  The C++ buffer preserves identical
 * interleaving and indexing when viewed as complex<double>.
 *
 * @note In the original Fortran implementation, u(G,q) is always
 *       transformed here; this C++ version preserves the same logic
 *       and assumptions.
 */

void cvdw_DF::generate_potentials(int Nqs,
                                  int ispin,
                                  int nfft3d, int n2ft3d,
                                  double *ufunc,     // [n2ft3d * Nqs] real-space ufunc(r,j)
                                  double *q0,        // xce
                                  double *drho,      // xcp
                                  double *ddrho,     // xxe
                                  double *tmpexc,    // xce + nfft3d
                                  double *tmpfn,     // xxp
                                  double *tmpfdn,    // rho
                                  double *exc,       // output exc(nfft3d)
                                  double *fn,        // output fn(nfft3d, ispin)
                                  double *fdn)
{
    // ---- 2D decomposition in j (same logic as generate_theta_g) ----
    int taskid_j = myparall->taskid_j();
    int np_j     = myparall->np_j();

    int base = Nqs / np_j;
    int rem  = Nqs % np_j;

    int nj, jstart;
    if (taskid_j < rem)
    {
        nj     = base + 1;
        jstart = taskid_j * (base + 1);                // 0-based
    }
    else
    {
        nj     = base;
        jstart = rem * (base + 1) + (taskid_j - rem) * base;
    }

    // ---- zero local accumulators ----
    std::fill(tmpexc, tmpexc + nfft3d, 0.0);
    for (int ms = 0; ms < ispin; ++ms)
    {
        std::fill(tmpfn  + ms * nfft3d, tmpfn  + (ms + 1) * nfft3d, 0.0);
        std::fill(tmpfdn + ms * nfft3d, tmpfdn + (ms + 1) * nfft3d, 0.0);
    }

    // NOTE: In the original Fortran, there is a call:
    //   Grsm_gh_fftb(nfft3d, nj, ufunc(1,jstart))
    // which does a G->R back FFT on ufunc.
    // Here we assume ufunc is already in real space (or that the FFT
    // is handled elsewhere). If you later wire a proper G->R FFT,
    // that call should go here.

    if (nj > 0)
    {
        //mygrid->nbngh_fftb(0,nj,ufunc+jstart*n2ft3d);
        for (int j=0; j<nj; ++j) 
        {
           int jj = jstart + j;
           // complex functions
           mygrid->c_unpack(0, ufunc+jj*n2ft3d);
           mygrid->cr_pfft3b(0,ufunc+jj*n2ft3d);

           // tranformed to realspace functions
           mygrid->cr_copy(ufunc+jj*n2ft3d, ufunc+jj*n2ft3d);

        }
       
        // ---- main loops: i = real-space grid, j = q index block ----
        for (int i=0; i<nfft3d; ++i)
        {
            double q0i = q0[i];

            for (int jj = 0; jj<nj; ++jj)
            {
                int j = jstart + jj;   // 0-based index for this processor’s j

                double pj, dpj;
                // poly() uses Fortran-style 1-based i, so pass (j+1)
                // and returns pj, dpj
                // (poly is the C++ version of vdw_DF_poly)
                // signature: void vdw_DF::poly(int i, double x, double &p, double &dp);
                // We'll call it through a lambda capturing i, but since this
                // helper is free-standing, we assume a global poly-like function
                // exists or is provided by the caller.
                // ==> Here we just *declare* it and assume the definition
                //     below in this file:
                //extern void vdw_DF_poly_wrapper(int i, double x, double &p, double &dp);
                poly(j+1, q0i, pj, dpj);

                double u = ufunc[i + j*n2ft3d];  // ufunc(r,i,j)

                tmpexc[i] += 0.5 * pj * u;

                for (int ms = 0; ms < ispin; ++ms)
                {
                    double dr  = drho [i + ms * nfft3d];
                    double ddr = ddrho[i + ms * nfft3d];

                    tmpfn [i + ms * nfft3d] += (pj + dpj * dr) * u;
                    tmpfdn[i + ms * nfft3d] += (dpj * ddr) * u;
                }
            }
        }
    }

    // ---- MPI reductions (sum across all ranks) ----
    myparall->Vector_SumAll(2, nfft3d,        tmpexc);
    myparall->Vector_SumAll(2, ispin*nfft3d,  tmpfn);
    myparall->Vector_SumAll(2, ispin*nfft3d,  tmpfdn);

    // ---- accumulate into global exc, fn, fdn ----
    for (int i=0; i<nfft3d; ++i)
        exc[i] += tmpexc[i];

    for (int ms=0; ms<ispin; ++ms)
    {
        double *fn_ms  = fn  + ms * nfft3d;
        double *fdn_ms = fdn + ms * nfft3d;
        double *tmpfn_ms  = tmpfn  + ms * nfft3d;
        double *tmpfdn_ms = tmpfdn + ms * nfft3d;

        for (int i=0; i<nfft3d; ++i)
        {
            fn_ms [i] += tmpfn_ms [i];
            fdn_ms[i] += tmpfdn_ms[i];
        }
    }
}



/**************************************
 *                                    *
 *     cvdw_DF::generate_theta_g      *
 *                                    *
 **************************************/
/**
 * @brief Build the saturated q₀ field and nonlocal kernel amplitudes
 *        θ(G,q) for the vdW-DF functional.
 *
 * This routine performs the real-space part of the vdW-DF kernel
 * construction and then FFTs to reciprocal space:
 *
 *  1. For each real-space grid point i, form the local quantity
 *     q₀(i) from the LDA/GGA-like inputs (rho, agr, vxc, exc, vxx, exx)
 *     using the standard vdW-DF prescription and the parameter Zab.
 *
 *  2. Apply a saturation mapping q₀ → q₀_sat ∈ [qmin, qmax] via
 *     a smooth exponential construction.  At the same time, compute
 *     the derivatives dq₀/dρ and dq₀/d(∇ρ²) and accumulate them into
 *     vxc and exx, respectively.  The array exc is overwritten by
 *     the saturated q₀_sat field.
 *
 *  3. For each local q₀_sat(i) and each kernel index j in this
 *     MPI task’s j-block, evaluate the spline-polynomial p_j(q₀_sat)
 *     via cvdw_DF::poly(), and build the real-space kernel amplitudes
 *       θ(r_i, j) = ρ(i) * p_j(q₀_sat(i)).
 *
 *  4. For each local j, transform θ(r,j) → θ(G,j) using:
 *       - rc_copy()   to expand real scalars into interleaved
 *                     complex storage [Re,Im] with Im = 0
 *       - rc_pfft3f() forward 3D FFT r → G
 *       - c_pack() / c_pack_SMul() packing and normalization
 *     On exit, θ is stored in packed complex reciprocal-space form
 *     for all j on this task:
 *       theta[j * n2ft3d + 2*k]   = Re{ θ(G_k, j) }
 *       theta[j * n2ft3d + 2*k+1] = Im{ θ(G_k, j) }.
 *
 *  5. Perform a global MPI reduction over all 2D j-tasks so that
 *     θ(G,j) is consistent across the full parallel decomposition.
 *
 * Parallel layout:
 *  - The q-index j is block-distributed over np_j tasks in the
 *    second (j) dimension, with local size nj and starting index
 *    jstart on this rank.
 *  - Real-space points i = 0..nfft3d-1 are local to each rank
 *    (no further decomposition in this routine).
 *
 * @param[in]  Nqs     Number of q-mesh points (kernel channels).
 * @param[in]  ispin   Number of spin channels (1 or 2).
 * @param[in]  nfft3d  Number of real-space grid points (per rank).
 * @param[in]  n2ft3d  Length of the packed complex array per j
 *                     (≥ 2 * nfft3d, as required by Cneb FFT layout).
 * @param[in]  Zab     vdW-DF parameter controlling the Cxi prefactor.
 * @param[in]  qmin    Lower bound for q₀ before saturation.
 * @param[in]  qmax    Upper bound and saturation scale for q₀.
 * @param[in]  rho     Spin-summed density ρ(r) on the real-space grid
 *                     (size at least nfft3d).
 * @param[in]  agr     Gradient-related quantity (e.g. |∇ρ|² or similar),
 *                     defined on the same grid (size ≥ nfft3d).
 * @param[in,out] vxc  Exchange–correlation potential array; on entry
 *                     contains LDA/GGA-like pieces; on exit it is
 *                     updated with contributions from dq₀/dρ.
 *                     Laid out as vxc[i + s*nfft3d], s = 0..ispin-1.
 * @param[in,out] exc  Exchange–correlation energy density; on entry
 *                     holds local (e.g. GGA) pieces; on exit exc[i]
 *                     is overwritten by the saturated q₀_sat(i).
 * @param[in,out] vxx  Exchange-only potential; used in building q₀
 *                     and dq₀/dρ. May be modified in place.
 * @param[in,out] exx  Exchange-only energy density; used to form q₀
 *                     and its gradient dependence; on exit contains
 *                     contributions proportional to dq₀/d(∇ρ²).
 * @param[in,out] theta
 *                     Kernel amplitudes. On entry, this array is
 *                     zeroed and filled with θ(r,j) in real-space
 *                     (only the first nfft3d entries per j are used).
 *                     After the FFT/packing steps and MPI reduction,
 *                     it holds θ(G,j) in packed complex form for
 *                     all q-channels.
 *
 * @note This routine assumes that the spline tables for p_j(q)
 *       (qmesh, ya, ya2) have been initialized via init_poly(),
 *       and that the underlying Cneb / Parallel objects are
 *       fully configured for the FFT and 2D decomposition.
 */

void cvdw_DF::generate_theta_g(
        int Nqs,
        int ispin,
        int nfft3d, int n2ft3d,
        double Zab,
        double qmin,
        double qmax,
        const double *rho,
        const double *agr,
        double *vxc,
        double *exc,
        double *vxx,
        double *exx,
        double *theta)
{
    // ---- get parallel info ----
    //int tid     = myparall->threadid();
    //int nthr    = myparall->nthreads();

    //std::cout << "qmin=" << qmin << " qmax=" << qmax << std::endl;
    int taskid_j = myparall->taskid_j();
    int np_j     = myparall->np_j();

    int nx = mygrid->nx;
    int ny = mygrid->ny;
    int nz = mygrid->nz;
    double scal1 = 1.0 / double(nx * ny * nz);

    // ---- block decomposition over j ----
    int base = Nqs / np_j;
    int rem  = Nqs % np_j;

    int nj, jstart;
    if (taskid_j < rem) 
    {
       nj = base + 1;
       jstart = taskid_j * (base + 1);
    } 
    else 
    {
       nj = base;
       jstart = rem * (base + 1) + (taskid_j - rem) * base;
    }

    // zero theta
    std::fill(theta, theta + size_t(n2ft3d)*Nqs, 0.0);

    if (nj > 0)
    {
        const double pi = M_PI;
        const double Cf  = pow(3.0 * pi * pi, 1.0/3.0);
        const double A   = -4.0 * pi / 3.0;
        const double Cxi = Zab / (36.0 * Cf);

        const double onethird = 1.0/3.0;
        const double frthrd   = 4.0/3.0;
        const double elthrd   = 11.0/3.0;
        const double dncut    = 1e-12;

        // ---- main loop over real-space grid ----
        for (int i=0; i<nfft3d; ++i)
        {
           double rh = rho[i];

           double q0sat = 0.0;

           if (rh >= dncut)
           {
              double temp = (agr[i] / pow(rh, frthrd));
              double xi  = Cxi * temp * temp;
              double dxi = 2.0 * Cxi * agr[i] * pow(1.0 / pow(rh, frthrd), 2);

              double exgga = exx[i] - xi * exx[i];
              double vxgga = vxx[i] - xi * (vxx[i] - elthrd * exx[i]);

              if ((vxgga - exgga) < 0.0) 
              {
                 xi = 0.0;
                 dxi = 0.0;
              }

              double q0 = A * (exc[i] - exx[i] * xi);

              double dq0drho[2] = {0.0, 0.0};
              double dq0ddrho   = 0.0;

              if (q0 < qmin) 
              {
                 q0 = qmin;
              } 
              else 
              {
                 dq0drho[0] = A*((vxc[i] - exc[i]) - xi*(vxx[i] - elthrd*exx[i]))/rh;
                 if (ispin==2)
                     dq0drho[1] = A*((vxc[i+nfft3d] - exc[i])
                                - xi*(vxx[i+nfft3d] - elthrd*exx[i]))/rh;

                 dq0ddrho = -A * exx[i] * dxi;
              }

              double tsum  = 0.0;
              double dtsum = 0.0;
              for (int k = 1; k <= 12; k++) 
              {
                 tsum  += std::pow(q0/qmax, k) / double(k);
                 dtsum += std::pow(q0/qmax, k-1);
              }
              q0sat = qmax * (1.0 - std::exp(-tsum));
              double dq0satdq0 = std::exp(-tsum) * dtsum;

              exc[i] = q0sat;
              for (int ms = 0; ms < ispin; ++ms)
                 vxc[i + ms*nfft3d] = rh * dq0satdq0 * dq0drho[ms];

              exx[i] = rh * dq0satdq0 * dq0ddrho;
           }
           else
           {
              q0sat = qmax;
              exc[i] = qmax;
              for (int ms=0; ms<ispin; ++ms)
                  vxc[i + ms*nfft3d] = 0.0;
              exx[i] = 0.0;
           }

           // ---- now fill θ(i,j) for this processor's j-block ----
           for (int j=0; j<nj; j++)
           {
              int jj = jstart + j;
              double pj, dpj;
              poly(jj+1, q0sat, pj, dpj);
              theta[i + jj*n2ft3d] = rho[i] * pj;
            //std::cout << "i=" << i << " j=" << j << " pj=" << pj << std::endl;
           }
        }


        // ---- transform θ(r,j) → θ(G,j) ----
        for (int j=0; j<nj; j++) 
        {
           int jj = jstart + j;
           //mygrid->r_zero_ends(theta + jj*n2ft3d);
           //std::cout << "jj=" << jj << " rho*theta_r=" << Efmt(13,8) << mygrid->rr_dot(rho,theta+jj*n2ft3d) << std::endl;

           mygrid->rc_copy(theta+jj*n2ft3d,theta+jj*n2ft3d);
           mygrid->rc_pfft3f(0,theta+jj*n2ft3d);
           mygrid->c_pack(0,theta+jj*n2ft3d);
           mygrid->c_pack_SMul(0,scal1,theta+jj*n2ft3d);
        }
        //mygrid->nh_zero_ends(nj,theta +jstart*n2ft3d);
        //mygrid->nbnhg_fftf(0,nj,theta +jstart*n2ft3d);
        //mygrid->nbnhg_SMul(0,nj,scal1,theta +jstart*n2ft3d);
    }

    // ---- global reduce sum across processors ----
    myparall->Vector_SumAll(2, Nqs*n2ft3d, theta);
}



/********************************
 *                              *
 *         Constructors         *
 *                              *
 ********************************/
/**
 * @brief Construct a van-der-Waals kernel object (vdW-DF).
 *
 * Loads the vdW kernel tables, initializes q-mesh polynomials,
 * and allocates local work arrays for xcp, xce, rho, theta, ufunc, etc.
 * 
 * @param inmygrid  Pointer to the real/reciprocal-space grid object (Cneb)
 *                  providing FFT, packed-G indexing, parallel decomposition,
 *                  and grid geometry.
 * @param control   Control2 object providing input parameters and
 *                  location of data directories.
 * @param is_vdw2   If true, the vdW2 kernel is selected (Zab = -1.887),
 *                  otherwise the original vdW-DF kernel is used (Zab = -0.8491).
 */
cvdw_DF::cvdw_DF(Cneb *inmygrid, Control2 &control, bool is_vdw2)
{
   mygrid   = inmygrid;
   myparall = mygrid->c3db::parall;
   has_vdw = true;

   npack0 = mygrid->npack(0);
   nfft3d = mygrid->nfft3d;
   n2ft3d = mygrid->n2ft3d;

   bool oprint = (myparall->is_master() && control.print_level("medium"));


   const std::string nwpw_vdw_qmesh = std::string(Nwpw_LIBRARYVDW_Default) + "/vdw_qmesh.dat";
   //const char *nwpw_libraryps = Nwpw_LIBRARYPS_Default + "/VDW/vdw_qmesh.dat";

   char datafile[256];
   strcpy(datafile, "vdw_kernels.dat");
   control.add_permanent_dir(datafile);
   //std::cout << "nwpw_vdw = " << nwpw_vdw_qmesh << " datafile=" << datafile << std::endl;

   int ifound = cfileexists(datafile);
   if (ifound == 0)
   {
      if (oprint) std::cout << " Generating VDW kernel filename:" << datafile << std::endl;
      //vdw_DF_kernel_gen_data(datafile)
      vdw_DF_kernel_gen_data(myparall,datafile,nwpw_vdw_qmesh.c_str());
   }

   if (myparall->is_master())
   {
      openfile(5,datafile,"r");
      iread(5,&Nqs,1);
      iread(5,&nk,1);
      dread(5,&kmax,1);
   }
   myparall->Brdcst_iValue(0,MASTER,&Nqs);
   myparall->Brdcst_iValue(0,MASTER,&nk);
   myparall->Brdcst_Values(0,MASTER,1,&kmax);
   nk1 = nk + 1;


   theta  = new (std::nothrow) double[Nqs*n2ft3d]();
   ufunc  = new (std::nothrow) double[Nqs*n2ft3d]();

   qmesh  = new (std::nothrow) double[Nqs]();
   ya     = new (std::nothrow) double[Nqs*Nqs]();
   ya2    = new (std::nothrow) double[Nqs*Nqs]();
   gphi   = new (std::nothrow) double[nk1]();
   phi    = new (std::nothrow) double[nk1*Nqs*(Nqs+1)]();

   xcp    = new (std::nothrow) double[2*nfft3d]();
   xce    = new (std::nothrow) double[2*nfft3d]();
   xxp    = new (std::nothrow) double[2*nfft3d]();
   xxe    = new (std::nothrow) double[2*nfft3d]();
   rho    = new (std::nothrow) double[2*nfft3d]();
   Gpack  = new (std::nothrow) double[npack0]();
   nxpack = new (std::nothrow) int[npack0]();


   if (myparall->is_master())
   {
      dread(5,qmesh,Nqs);
      dread(5,phi,nk1*Nqs*(Nqs+1));
   }
   myparall->Brdcst_Values(0, MASTER, Nqs, qmesh);
   myparall->Brdcst_Values(0, MASTER, nk1*Nqs*(Nqs+1), phi);

    
   init_poly();   // <<<=== Required (Fortran does it right after reading qmesh)

   double dk = kmax/double(nk);
   for (int k=0; k<=nk; ++k)
      gphi[k] = k*dk;

   double *Gx = mygrid->Gpackxyz(0,0);
   double *Gy = mygrid->Gpackxyz(0,1);
   double *Gz = mygrid->Gpackxyz(0,2);
   for (int k=0; k<npack0; ++k)
   {
      double gg = std::sqrt(Gx[k]*Gx[k] + Gy[k]*Gy[k] + Gz[k]*Gz[k]);
      Gpack[k] = gg;
         
      int nx = gg/dk;
      nxpack[k] = util_splint_nx(gphi,nx,gg,nk1);
      //std::cout << k << " " << nx << " " << gg << " " << nxpack[k] << std::endl;
   }



   if (is_vdw2)
      Zab = -1.887;
   else
      Zab = -0.8491;

   qmax = qmesh[Nqs-1];
   qmin = 0.0;
}



/********************************
 *                              *
 *         evaluate             *
 *                              *
 ********************************/
/**
 * @brief Evaluate the nonlocal van der Waals contribution (vdW-DF) to
 *        the exchange–correlation energy density and potentials.
 *
 * This routine is the top-level driver for the C++ vdW-DF implementation.
 * Given spin-resolved densities and (optionally) a GGA-like gradient
 * measure, it computes:
 *
 *  - the local (LDA) exchange–correlation pieces via ::v_exc
 *  - the (Dirac) exchange pieces for the spin-unpolarized case via ::v_dirac
 *  - the total (spin-summed) density \f$\rho(\mathbf{r})\f$
 *  - the nonlocal vdW kernel quantities \f$\theta(\mathbf{G},q)\f$
 *  - the auxiliary kernel contraction \f$u(\mathbf{G},q)\f$
 *  - and finally accumulates the nonlocal contribution into
 *    \c exc (energy density), \c fn (potential-like term) and
 *    \c fdn (density derivative term).
 *
 * The logic mirrors the original Fortran vdW-DF driver:
 *
 *  1. Call ::v_exc to build LDA exchange–correlation parts into
 *     internal work arrays (\c xcp, \c xce, \c rho).
 *  2. For the spin-unpolarized case (ispin == 1), call ::v_dirac to
 *     obtain the Dirac exchange terms (\c xxp, \c xxe).
 *  3. Build the spin-summed density \f$\rho(\mathbf{r}) = \sum_\sigma n_\sigma(\mathbf{r})\f$
 *     via generate_rho().
 *  4. Construct the q0 field and the real-space kernel amplitudes
 *     \f$\theta(\mathbf{r}, q)\f$, then FFT them to \f$\theta(\mathbf{G}, q)\f$
 *     in generate_theta_g().
 *  5. Contract \f$\theta(\mathbf{G}, q)\f$ with the pretabulated kernel
 *     to obtain \f$u(\mathbf{G}, q)\f$ via generate_ufunc().
 *  6. Transform \f$u(\mathbf{G}, q)\f$ back to real space and accumulate
 *     the nonlocal vdW-DF contributions to \c exc, \c fn and \c fdn
 *     using generate_potentials().
 *
 * All MPI / 2D-decomposition details are handled internally through
 * the associated Cneb / Parallel objects stored in the cvdw_DF instance.
 *
 * @param[in]  ispin  Number of spin channels (1 or 2).
 * @param[in]  dn     Spin densities on the real-space grid, laid out as
 *                    dn[i + s * nfft3d] with s = 0..ispin-1.
 * @param[in]  agr    Gradient-related quantity (GGA-like), defined on the
 *                    same real-space grid as \c dn (size at least nfft3d).
 * @param[out] exc    Exchange–correlation energy density on the grid
 *                    (size at least nfft3d). The vdW-DF contribution is
 *                    added to any pre-existing content in \c exc.
 * @param[out] fn     Potential-like term, dimensioned as fn[i + s * nfft3d]
 *                    for s = 0..ispin-1; vdW-DF contributions are added in place.
 * @param[out] fdn    Density-derivative term with the same spin layout as
 *                    \c fn; vdW-DF contributions are added in place.
 *
 * @note Internal work arrays (xcp, xce, xxp, xxe, rho, theta, ufunc, etc.)
 *       are owned and managed by the cvdw_DF object.
 * @note This routine assumes the cvdw_DF instance has been fully
 *       constructed and initialized (q-mesh, spline tables, packed G-vectors).
 */
void cvdw_DF::evaluate(int ispin, const double *dn, const double *agr,
                      double *exc, double *fn, double *fdn)
{
    // 1. LDA pieces
    v_exc(ispin, nfft3d, const_cast<double*>(dn), xcp, xce, rho);
    //std::cout << "VXCA = " << Ffmt(13,9) << mygrid->rr_dot(dn,xce) << std::endl;
    //std::cout << "VXCAA= " << Ffmt(13,9) << mygrid->rr_dot(dn,xcp) << std::endl;
    if (ispin == 1)
        v_dirac(ispin, nfft3d, const_cast<double*>(dn), xxp, xxe, rho);
    //std::cout << "VXCB = " << Ffmt(13,9) << mygrid->rr_dot(dn,xxp) << std::endl;

    // 2. build rho
    generate_rho(ispin, nfft3d, dn, rho);
    //mygrid->r_zero_ends(rho);
    //std::cout << "RHOA = " << Ffmt(13,9) << mygrid->rr_dot(rho,rho) << std::endl;

    // 3. theta(G)
    generate_theta_g(Nqs, ispin, nfft3d, n2ft3d, Zab, qmin, qmax, rho, agr, xcp, xce, xxp, xxe, theta);

  // 2. IMPORTANT: generate_theta_g modifies xcp,xce,xxp,xxe
  //    Now compute the theta-contractions EXACTLY as Fortran does:
  
  //double dum1 = mygrid->rr_dot(rho, xcp);
  //double dum2 = mygrid->rr_dot(rho, xce);
  //std::cout << "theta xcp = " << Ffmt(13,9) << dum1 << std::endl;
  //std::cout << "theta xce = " << Ffmt(13,9) << dum2 << std::endl;
  
  //dum1 = mygrid->rr_dot(rho, xxp);
  //dum2 = mygrid->rr_dot(rho, xxe);
  //std::cout << "theta xxp = " << Ffmt(13,9) << dum1 << std::endl;
  //std::cout << "theta xxe = " << Ffmt(13,9) << dum2 << std::endl;
    //std::cout << "theta xcp = " << Ffmt(13,9) << mygrid->rr_dot(rho,xcp) << std::endl;
    //std::cout << "theta xce = " << Ffmt(13,9) << mygrid->rr_dot(rho,xce) << std::endl;
    //std::cout << "theta xxp = " << Ffmt(13,9) << mygrid->rr_dot(rho,xxp) << std::endl;
    //std::cout << "theta xxe = " << Ffmt(13,9) << mygrid->rr_dot(rho,xxe) << std::endl;

  //dum1 = mygrid->cc_pack_dot(0,theta, theta);
  //std::cout << "theta*theta = " << Efmt(13,9) << dum1 << std::endl;
  //for (auto jj=0; jj<Nqs; ++jj)
  //{
   //  dum1 = mygrid->cc_pack_dot(0,theta+jj*n2ft3d, theta+jj*n2ft3d);
    // std::cout << "jj=" << jj << " theta*theta = " << Efmt(13,9) << dum1 << std::endl;
  //}


    // 4. ufunc(G,i)
    generate_ufunc(nk1, Nqs, gphi, phi, npack0, nfft3d, Gpack, nxpack,
                   reinterpret_cast<const std::complex<double>*>(theta), 
                   reinterpret_cast<std::complex<double>*>(ufunc));
    //std::cout << "rho*ufunc = " << Ffmt(13,9) << mygrid->rr_dot(rho,ufunc) << std::endl;


   // std::cout << "pre xce = " << Ffmt(13,9) << mygrid->rr_dot(rho,xce) << std::endl;

    // 5. exc, fn, fdn
    generate_potentials(Nqs, ispin, nfft3d, n2ft3d, ufunc, xce, xcp, xxe,
                        xce+nfft3d, xxp, rho, exc, fn, fdn);
    //std::cout << "xce = " << Ffmt(13,9) << mygrid->rr_dot(rho,xce) << std::endl;
}



}



